{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set: Tensorflow\n",
    "> Tangqi Feng\n",
    "\n",
    "These problems relate to the Python package [Tensorflow](https://www.tensorflow.org/).\n",
    "We will again use the famous [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.1' '3.5' '1.4' '0.2' 'setosa']\n",
      "['4.9' '3' '1.4' '0.2' 'setosa']\n",
      "['4.7' '3.2' '1.3' '0.2' 'setosa']\n",
      "['4.6' '3.1' '1.5' '0.2' 'setosa']\n",
      "['5' '3.6' '1.4' '0.2' 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# adapt from https://github.com/antonrufino/TensorFlow-IrisNN/blob/master/iris_nn.py\n",
    "# inport numpy\n",
    "import numpy as np\n",
    "# load Iris data set as str,because the 'species' column's type is str\n",
    "OriginalData = np.loadtxt(\"iris.csv\",str, delimiter=\",\", skiprows=1, unpack=True)\n",
    "iris = OriginalData.transpose()\n",
    "\n",
    "# the data stored like this:\n",
    "for i in range(5):\n",
    "    print(iris[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the data into training and testing\n",
    "Split the data set into a training set and a testing set.\n",
    "You should investigate the best way to do this, and list any online references used in your notebook.\n",
    "If you wish to, you can write some code to randomly separate the data on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species: setosa --> 0 --> [ 1.  0.  0.]\n",
      "species: setosa --> 0 --> [ 1.  0.  0.]\n",
      "species: versicolor --> 1 --> [ 0.  1.  0.]\n",
      "species: virginica --> 2 --> [ 0.  0.  1.]\n",
      "species: virginica --> 2 --> [ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Randomly split the data into training and testing\n",
    "# Adapt from : https://stackoverflow.com/questions/17412439/how-to-split-data-into-trainset-and-testset-randomly\n",
    "np.random.shuffle(iris)\n",
    "# define 100 set of data for training, and 50 for test\n",
    "train, test = iris[:100], iris[100:]\n",
    "# get input data (sepal_length, sepal_width, petal_length, petal_width)\n",
    "in_train = train[:,:4]\n",
    "in_test = test[:,:4]\n",
    "# get output data\n",
    "out_train = train[:,4]\n",
    "out_test = test[:,4]\n",
    "# convert inputs data from type(str) to float\n",
    "in_train = np.array(in_train).astype(np.float)\n",
    "in_test = np.array(in_test).astype(np.float)\n",
    "# get a list of output categories as 'one-hot vectors'\n",
    "# a one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension\n",
    "# in this case,convert like this:\n",
    "#    setosa      ->[1,0,0]\n",
    "#    virginica   ->[0,1,0]\n",
    "#    versicolor  ->[0,0,1]\n",
    "# np.unique --> return a unique list in array, \n",
    "# 'return_inverse=True' will return the index number of such unique element\n",
    "# more details: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html\n",
    "uniq_test, ids_test = np.unique(out_test, return_inverse=True)\n",
    "uniq_train, ids_train = np.unique(out_train, return_inverse=True)\n",
    "# np_utils.to_categorical --> Converts a class vector (integers) to binary class matrix.\n",
    "# more details: https://keras.io/utils/\n",
    "from keras.utils import np_utils\n",
    "onehot_train = np_utils.to_categorical(ids_train, len(uniq_train))\n",
    "onehot_test = np_utils.to_categorical(ids_test, len(uniq_test))\n",
    "# after np.unique & np_utils.to_categorical two operation\n",
    "# the data like this: \n",
    "for i in range(5):\n",
    "    print('species: '+(str)(out_test[i])+' --> '+(str)(ids_test[i])\\\n",
    "          +' --> '+(str)(onehot_test[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Tensorflow to create model\n",
    "Use Tensorflow to create a model to predict the species of Iris from a flower's sepal width, sepal length, petal width, and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a set of data contains: sepal_length, sepal_width, petal_length, petal_width and species\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "# create a model:\n",
    "# input layer\n",
    "# input_data [None,4] means:None: do not deside the number of set of input numbers\n",
    "#                           4: (sepal_length, sepal_width, petal_length, petal_width)\n",
    "x = tf.placeholder(tf.float32,[None,4])\n",
    "# output_data (species) means:None: do not deside the number of set of input numbers\n",
    "#                           3: species:(setosa,versicolor,virginica)\n",
    "y = tf.placeholder(tf.float32,[None,3])\n",
    "# output layer\n",
    "# tf.truncated_normal --> outputs random values from a truncated normal distribution\n",
    "# 'stddev' is the standard deviation of the truncated normal distribution.\n",
    "# method details: https://www.tensorflow.org/api_docs/python/tf/truncated_normal\n",
    "# here, designed a [4,3] matrix for Weight(W), simply means 4 data inputs and 3 outputs\n",
    "W = tf.Variable(tf.truncated_normal([4,3],stddev=0.1))\n",
    "# set bias for output value, because output 3 values, so the size of bias is [3]\n",
    "b = tf.Variable(tf.zeros([3]) + 1)\n",
    "# tf.matmul --> a method multiplies matrix\n",
    "# tf.nn.softmax --> softmax gives us a list of values between 0 and 1 that add up to 1\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "Use the training set to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# here, use cross_entropy and softmax method:\n",
    "# cross_entropy function --> as the loss function\n",
    "# softmax is the thing to do, because softmax gives us a list of values between 0 and 1 that add up to 1\n",
    "# tf.nn.softmax_cross_entropy_with_logits method combines cross_entropy and softmax\n",
    "# more details: https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# use GradientDescent optimizer to train\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# initial glabal variables\n",
    "init = tf.global_variables_initializer()\n",
    "# create loop to train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for eposh in range(100):    # times for training all training)set\n",
    "        sess.run(train_step,{x:in_train, y:onehot_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model\n",
    "Use the testing set to test your model, clearly calculating and displaying the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0,Testing Accuracy 0.34,Testing Error Rate 0.659999996424\n",
      "Iter 1,Testing Accuracy 0.34,Testing Error Rate 0.659999996424\n",
      "Iter 2,Testing Accuracy 0.46,Testing Error Rate 0.539999991655\n",
      "Iter 3,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 4,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 5,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 6,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 7,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 8,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 9,Testing Accuracy 0.3,Testing Error Rate 0.699999988079\n",
      "Iter 10,Testing Accuracy 0.32,Testing Error Rate 0.680000007153\n",
      "Iter 11,Testing Accuracy 0.52,Testing Error Rate 0.480000019073\n",
      "Iter 12,Testing Accuracy 0.64,Testing Error Rate 0.360000014305\n",
      "Iter 13,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 14,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 15,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 16,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 17,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 18,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 19,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 20,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 21,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 22,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 23,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 24,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 25,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 26,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 27,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 28,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 29,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 30,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 31,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 32,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 33,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 34,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 35,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 36,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 37,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 38,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 39,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 40,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 41,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 42,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 43,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 44,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 45,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 46,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 47,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 48,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 49,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 50,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 51,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 52,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 53,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 54,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 55,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 56,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 57,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 58,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 59,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 60,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 61,Testing Accuracy 0.66,Testing Error Rate 0.339999973774\n",
      "Iter 62,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 63,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 64,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 65,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 66,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 67,Testing Accuracy 0.68,Testing Error Rate 0.319999992847\n",
      "Iter 68,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 69,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 70,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 71,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 72,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 73,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 74,Testing Accuracy 0.7,Testing Error Rate 0.300000011921\n",
      "Iter 75,Testing Accuracy 0.74,Testing Error Rate 0.259999990463\n",
      "Iter 76,Testing Accuracy 0.74,Testing Error Rate 0.259999990463\n",
      "Iter 77,Testing Accuracy 0.74,Testing Error Rate 0.259999990463\n",
      "Iter 78,Testing Accuracy 0.74,Testing Error Rate 0.259999990463\n",
      "Iter 79,Testing Accuracy 0.76,Testing Error Rate 0.240000009537\n",
      "Iter 80,Testing Accuracy 0.78,Testing Error Rate 0.22000002861\n",
      "Iter 81,Testing Accuracy 0.8,Testing Error Rate 0.199999988079\n",
      "Iter 82,Testing Accuracy 0.8,Testing Error Rate 0.199999988079\n",
      "Iter 83,Testing Accuracy 0.8,Testing Error Rate 0.199999988079\n",
      "Iter 84,Testing Accuracy 0.8,Testing Error Rate 0.199999988079\n",
      "Iter 85,Testing Accuracy 0.8,Testing Error Rate 0.199999988079\n",
      "Iter 86,Testing Accuracy 0.82,Testing Error Rate 0.180000007153\n",
      "Iter 87,Testing Accuracy 0.82,Testing Error Rate 0.180000007153\n",
      "Iter 88,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 89,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 90,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 91,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 92,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 93,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 94,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 95,Testing Accuracy 0.84,Testing Error Rate 0.160000026226\n",
      "Iter 96,Testing Accuracy 0.86,Testing Error Rate 0.139999985695\n",
      "Iter 97,Testing Accuracy 0.86,Testing Error Rate 0.139999985695\n",
      "Iter 98,Testing Accuracy 0.86,Testing Error Rate 0.139999985695\n",
      "Iter 99,Testing Accuracy 0.86,Testing Error Rate 0.139999985695\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) # correct return true, otherwise return false\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # true->1.0   false->0\n",
    "# create loop to test\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for eposh in range(100):    # times for training all training)set\n",
    "        sess.run(train_step,{x:in_train, y:onehot_train})                  #train               \n",
    "        acc = sess.run(accuracy,{x:in_test, y:onehot_test})                #test\n",
    "        print(\"Iter \" + str(eposh) + \",Testing Accuracy \" + str(acc) + \",Testing Error Rate \" + str(1-acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
