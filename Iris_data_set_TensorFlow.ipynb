{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set: Tensorflow\n",
    "> Tangqi Feng\n",
    "\n",
    "These problems relate to the Python package [Tensorflow](https://www.tensorflow.org/).\n",
    "We will again use the famous [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1  3.5  1.4  0.2  1. ]\n",
      "[ 4.9  3.   1.4  0.2  1. ]\n",
      "[ 4.7  3.2  1.3  0.2  1. ]\n",
      "[ 4.6  3.1  1.5  0.2  1. ]\n",
      "[ 5.   3.6  1.4  0.2  1. ]\n"
     ]
    }
   ],
   "source": [
    "# adapt from https://github.com/antonrufino/TensorFlow-IrisNN/blob/master/iris_nn.py\n",
    "# inport numpy\n",
    "import numpy as np\n",
    "# load Iris data set\n",
    "OriginalData = np.loadtxt(\"iris.csv\",str, delimiter=\",\", skiprows=1, unpack=True)\n",
    "Iris = OriginalData.transpose()\n",
    "# change 4th column data (species name) to a number, make it calculatable\n",
    "#  setosa     ->   0\n",
    "#  virginica  ->   1\n",
    "#  versicolor ->   2\n",
    "Iris[Iris[:,4] == 'setosa',4] = '0';\n",
    "Iris[Iris[:,4] == 'versicolor',4] = '1';\n",
    "Iris[Iris[:,4] == 'virginica',4] = '2';\n",
    "# convert array(Iris) from type(str) to float\n",
    "Iris = np.array(Iris).astype(np.float)\n",
    "# the data stored like this:\n",
    "for i in range(5):\n",
    "    print(Iris[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use Tensorflow to create model\n",
    "Use Tensorflow to create a model to predict the species of Iris from a flower's sepal width, sepal length, petal width, and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "# a set of data contains: sepal_length, sepal_width, petal_length, petal_width and species\n",
    "# create a model\n",
    "x = tf.placeholder(tf.float32,[None,4])  #input_data  (sepal_length, sepal_width, petal_length, petal_width)\n",
    "y = tf.placeholder(tf.float32,[None,1])  #output_data (species)\n",
    "# tf.truncated_normal method from:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/truncated_normal\n",
    "W = tf.Variable(tf.truncated_normal([4,1],stddev=0.1))  # Weight ([4,1]: 4 input and 1 output)\n",
    "b = tf.Variable(tf.zeros([1]) + 1)                      # bias\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data into training and testing\n",
    "Split the data set into a training set and a testing set.\n",
    "You should investigate the best way to do this, and list any online references used in your notebook.\n",
    "If you wish to, you can write some code to randomly separate the data on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Randomly split the data into training and testing\n",
    "# Adapt from : https://stackoverflow.com/questions/17412439/how-to-split-data-into-trainset-and-testset-randomly\n",
    "np.random.shuffle(Iris)\n",
    "# define 100 set of data for training, and 50 for test\n",
    "training, test = Iris[:100], Iris[100:] \n",
    "print(training.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "Use the training set to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get input data_set and output data_set\n",
    "train_in = training[:,:4]    #(sepal_length, sepal_width, petal_length, petal_width)\n",
    "train_out = training[:,4:]   #(species)\n",
    "# use cross_entropy method: tf.nn.softmax_cross_entropy_with_logits method\n",
    "# https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# use GradientDescentOptimizer to train\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# initial glabal variables\n",
    "init = tf.global_variables_initializer()\n",
    "# create loop to train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for eposh in range(100):    # times for training all training)set\n",
    "        sess.run(train_step,{x:train_in, y:train_out})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model\n",
    "Use the testing set to test your model, clearly calculating and displaying the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 99,Testing Accuracy 0.44,Testing Error Rate 0.560000002384\n"
     ]
    }
   ],
   "source": [
    "# get input data_set and output data_set\n",
    "test_in = test[:,:4]    #(sepal_length, sepal_width, petal_length, petal_width)\n",
    "test_out = test[:,4:]   #(species)\n",
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(y,prediction) # correct return true, otherwise return false\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # true->1.0   false->0\n",
    "# create loop to test\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for eposh in range(100):    # times for training all training)set\n",
    "        sess.run(train_step,{x:train_in, y:train_out})                  #train               \n",
    "        acc = sess.run(accuracy,{x:test_in, y:test_out})                #test\n",
    "    print(\"Iter \" + str(eposh) + \",Testing Accuracy \" + str(acc) + \",Testing Error Rate \" + str(1-acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### there are some points infecting the Accuracy:\n",
    "### * define a number to represent a species (string cannot be used to calculate )\n",
    "### * randomly split train/test data set\n",
    "### * different cost-calculate method\n",
    "### * different Optimizer\n",
    "### * ... ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
